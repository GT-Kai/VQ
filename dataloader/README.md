# æ•°æ®åŠ è½½æ¨¡å— (DataLoader Module)

æœ¬æ¨¡å—æä¾›äº†ç”¨äºåŠ¨æ¼«å¤´åƒ VQ-VAE / VQ-GAN è®­ç»ƒçš„æ•°æ®åŠ è½½åŠŸèƒ½ï¼ŒåŸºäº PyTorch Lightning æ¡†æ¶å®ç°ã€‚

## ğŸ“‹ ç›®å½•

- [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§)
- [ä¾èµ–è¦æ±‚](#ä¾èµ–è¦æ±‚)
- [æ¨¡å—ç»“æ„](#æ¨¡å—ç»“æ„)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [API æ–‡æ¡£](#api-æ–‡æ¡£)
- [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
- [æ•°æ®æ ¼å¼è¦æ±‚](#æ•°æ®æ ¼å¼è¦æ±‚)

## âœ¨ åŠŸèƒ½ç‰¹æ€§

- âœ… **è‡ªåŠ¨æ•°æ®é›†åˆ’åˆ†**ï¼šè‡ªåŠ¨å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
- âœ… **æ•°æ®å¢å¼º**ï¼šæ”¯æŒæ°´å¹³ç¿»è½¬ã€é¢œè‰²æŠ–åŠ¨ç­‰å¢å¼ºç­–ç•¥
- âœ… **æ ‡å‡†åŒ–é¢„å¤„ç†**ï¼šè‡ªåŠ¨å°†å›¾åƒå½’ä¸€åŒ–åˆ° `[-1, 1]` èŒƒå›´
- âœ… **PyTorch Lightning é›†æˆ**ï¼šå®Œå…¨å…¼å®¹ Lightning æ¡†æ¶
- âœ… **é«˜æ€§èƒ½é…ç½®**ï¼šæ”¯æŒå¤šè¿›ç¨‹åŠ è½½ã€å†…å­˜å›ºå®šç­‰ä¼˜åŒ–
- âœ… **å¯å¤ç°æ€§**ï¼šæ”¯æŒéšæœºç§å­è®¾ç½®ï¼Œç¡®ä¿æ•°æ®é›†åˆ’åˆ†å¯å¤ç°

## ğŸ“¦ ä¾èµ–è¦æ±‚

ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹ä¾èµ–ï¼š

```bash
torch>=2.0.0
torchvision>=0.15.0
lightning>=2.0.0
Pillow>=9.0.0
```

å®‰è£…æ‰€æœ‰ä¾èµ–ï¼š

```bash
pip install -r requirements.txt
```

## ğŸ—ï¸ æ¨¡å—ç»“æ„

```
dataloader/
â”œâ”€â”€ dataModule.py    # ä¸»è¦æ•°æ®æ¨¡å—æ–‡ä»¶
â””â”€â”€ README.md        # æœ¬æ–‡æ¡£
```

### ä¸»è¦ç»„ä»¶

1. **AnimeFaceDataset**: PyTorch Dataset ç±»ï¼Œç”¨äºåŠ è½½å•å¼ å›¾ç‰‡
2. **AnimeDataModule**: PyTorch Lightning DataModule ç±»ï¼Œç®¡ç†æ•´ä¸ªæ•°æ®æµç¨‹
3. **get_train_transform()**: è·å–è®­ç»ƒæ—¶çš„æ•°æ®å˜æ¢ï¼ˆå«å¢å¼ºï¼‰
4. **get_val_transform()**: è·å–éªŒè¯æ—¶çš„æ•°æ®å˜æ¢ï¼ˆæ— å¢å¼ºï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
from dataloader.dataModule import AnimeDataModule
import lightning.pytorch as pl

# åˆ›å»ºæ•°æ®æ¨¡å—
datamodule = AnimeDataModule(
    data_dir="/path/to/your/images",
    image_size=256,
    batch_size=32,
    num_workers=4,
    val_split=0.2,
    train_augment=True,
)

# åœ¨ PyTorch Lightning è®­ç»ƒå™¨ä¸­ä½¿ç”¨
trainer = pl.Trainer()
trainer.fit(model, datamodule=datamodule)
```

### ç‹¬ç«‹ä½¿ç”¨ Dataset

```python
from dataloader.dataModule import AnimeFaceDataset, get_train_transform
from torch.utils.data import DataLoader

# åˆ›å»ºæ•°æ®é›†
transform = get_train_transform(image_size=256, augment=True)
dataset = AnimeFaceDataset(
    data_dir="/path/to/images",
    image_size=256,
    transform=transform,
)

# åˆ›å»º DataLoader
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
```

## ğŸ“š API æ–‡æ¡£

### `AnimeFaceDataset`

PyTorch Dataset ç±»ï¼Œç”¨äºåŠ è½½åŠ¨æ¼«å¤´åƒå›¾ç‰‡ã€‚

#### å‚æ•°

- `data_dir` (str): å›¾ç‰‡æ•°æ®ç›®å½•è·¯å¾„
- `image_size` (int, optional): ç›®æ ‡å›¾åƒå°ºå¯¸ï¼Œé»˜è®¤ `256`
- `transform` (transforms.Compose, optional): æ•°æ®å˜æ¢ï¼Œé»˜è®¤ `None`

#### è¿”å›å€¼

- `image` (torch.Tensor): å½¢çŠ¶ä¸º `(3, H, W)` çš„ tensorï¼Œå€¼åŸŸ `[-1, 1]`

#### ç¤ºä¾‹

```python
from dataloader.dataModule import AnimeFaceDataset, get_train_transform

transform = get_train_transform(image_size=256, augment=True)
dataset = AnimeFaceDataset(
    data_dir="/path/to/images",
    image_size=256,
    transform=transform,
)

# è·å–å•å¼ å›¾ç‰‡
image = dataset[0]  # shape: (3, 256, 256), range: [-1, 1]
```

---

### `AnimeDataModule`

PyTorch Lightning DataModule ç±»ï¼Œç®¡ç†è®­ç»ƒ/éªŒè¯æ•°æ®æµç¨‹ã€‚

#### å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `data_dir` | str | - | å›¾ç‰‡æ•°æ®ç›®å½•è·¯å¾„ï¼ˆå¿…éœ€ï¼‰ |
| `image_size` | int | `256` | ç›®æ ‡å›¾åƒå°ºå¯¸ |
| `batch_size` | int | `32` | æ‰¹æ¬¡å¤§å° |
| `num_workers` | int | `4` | DataLoader å·¥ä½œè¿›ç¨‹æ•° |
| `val_split` | float | `0.2` | éªŒè¯é›†æ¯”ä¾‹ï¼ˆ0-1ä¹‹é—´ï¼‰ |
| `train_augment` | bool | `True` | è®­ç»ƒæ—¶æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼º |
| `seed` | int | `42` | éšæœºç§å­ï¼ˆç”¨äºæ•°æ®é›†åˆ’åˆ†ï¼‰ |

#### æ–¹æ³•

- `setup(stage=None)`: è®¾ç½®æ•°æ®é›†ï¼Œåˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
- `train_dataloader()`: è¿”å›è®­ç»ƒé›† DataLoader
- `val_dataloader()`: è¿”å›éªŒè¯é›† DataLoader
- `test_dataloader()`: è¿”å›æµ‹è¯•é›† DataLoaderï¼ˆä¸éªŒè¯é›†ç›¸åŒï¼‰

#### ç¤ºä¾‹

```python
from dataloader.dataModule import AnimeDataModule

datamodule = AnimeDataModule(
    data_dir="/path/to/images",
    image_size=256,
    batch_size=32,
    num_workers=4,
    val_split=0.2,
    train_augment=True,
    seed=42,
)

# è®¾ç½®æ•°æ®é›†ï¼ˆLightning ä¼šè‡ªåŠ¨è°ƒç”¨ï¼Œä¹Ÿå¯æ‰‹åŠ¨è°ƒç”¨ï¼‰
datamodule.setup()

# è·å– DataLoader
train_loader = datamodule.train_dataloader()
val_loader = datamodule.val_dataloader()
```

---

### `get_train_transform()`

è·å–è®­ç»ƒæ—¶çš„æ•°æ®å˜æ¢ï¼ˆåŒ…å«æ•°æ®å¢å¼ºï¼‰ã€‚

#### å‚æ•°

- `image_size` (int, optional): ç›®æ ‡å›¾åƒå°ºå¯¸ï¼Œé»˜è®¤ `256`
- `augment` (bool, optional): æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œé»˜è®¤ `True`

#### è¿”å›

- `transforms.Compose`: æ•°æ®å˜æ¢ç»„åˆ

#### å˜æ¢æµç¨‹

1. Resize åˆ° `(image_size, image_size)`
2. ï¼ˆå¦‚æœ `augment=True`ï¼‰éšæœºæ°´å¹³ç¿»è½¬ï¼ˆp=0.5ï¼‰
3. ï¼ˆå¦‚æœ `augment=True`ï¼‰é¢œè‰²æŠ–åŠ¨ï¼ˆäº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦ Â±10%ï¼‰
4. è½¬æ¢ä¸º Tensor
5. å½’ä¸€åŒ–åˆ° `[-1, 1]`

#### ç¤ºä¾‹

```python
from dataloader.dataModule import get_train_transform

transform = get_train_transform(image_size=256, augment=True)
```

---

### `get_val_transform()`

è·å–éªŒè¯æ—¶çš„æ•°æ®å˜æ¢ï¼ˆä¸åŒ…å«æ•°æ®å¢å¼ºï¼‰ã€‚

#### å‚æ•°

- `image_size` (int, optional): ç›®æ ‡å›¾åƒå°ºå¯¸ï¼Œé»˜è®¤ `256`

#### è¿”å›

- `transforms.Compose`: æ•°æ®å˜æ¢ç»„åˆ

#### å˜æ¢æµç¨‹

1. Resize åˆ° `(image_size, image_size)`
2. è½¬æ¢ä¸º Tensor
3. å½’ä¸€åŒ–åˆ° `[-1, 1]`

#### ç¤ºä¾‹

```python
from dataloader.dataModule import get_val_transform

transform = get_val_transform(image_size=256)
```

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: åœ¨ PyTorch Lightning ä¸­ä½¿ç”¨

```python
import lightning.pytorch as pl
from dataloader.dataModule import AnimeDataModule
from model.vqvae_module import VQVAEModel

# åˆ›å»ºæ•°æ®æ¨¡å—
datamodule = AnimeDataModule(
    data_dir="/path/to/images",
    image_size=256,
    batch_size=32,
    num_workers=4,
    val_split=0.2,
)

# åˆ›å»ºæ¨¡å‹
model = VQVAEModel(...)

# åˆ›å»ºè®­ç»ƒå™¨
trainer = pl.Trainer(
    max_epochs=100,
    accelerator="gpu",
    devices=1,
)

# è®­ç»ƒ
trainer.fit(model, datamodule=datamodule)
```

### ç¤ºä¾‹ 2: æ‰‹åŠ¨æµ‹è¯•æ•°æ®åŠ è½½

```python
from dataloader.dataModule import AnimeDataModule

# åˆ›å»ºæ•°æ®æ¨¡å—
datamodule = AnimeDataModule(
    data_dir="/path/to/images",
    image_size=256,
    batch_size=4,
    num_workers=2,
    val_split=0.2,
    train_augment=True,
)

# è®¾ç½®æ•°æ®é›†
datamodule.setup()

# è·å–è®­ç»ƒé›† DataLoader
train_loader = datamodule.train_dataloader()
print(f"è®­ç»ƒé›†æ‰¹æ¬¡æ•°é‡: {len(train_loader)}")

# è·å–ä¸€ä¸ªæ‰¹æ¬¡
batch = next(iter(train_loader))
print(f"æ‰¹æ¬¡å½¢çŠ¶: {batch.shape}")  # (batch_size, 3, 256, 256)
print(f"æ‰¹æ¬¡å€¼åŸŸ: [{batch.min():.3f}, {batch.max():.3f}]")  # åº”è¯¥åœ¨ [-1, 1] èŒƒå›´å†…

# è·å–éªŒè¯é›† DataLoader
val_loader = datamodule.val_dataloader()
val_batch = next(iter(val_loader))
print(f"éªŒè¯æ‰¹æ¬¡å½¢çŠ¶: {val_batch.shape}")
```

### ç¤ºä¾‹ 3: è‡ªå®šä¹‰æ•°æ®å¢å¼º

```python
from dataloader.dataModule import AnimeFaceDataset
from torchvision import transforms
from torch.utils.data import DataLoader

# è‡ªå®šä¹‰å˜æ¢
custom_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomHorizontalFlip(p=0.5),
    # æ·»åŠ å…¶ä»–è‡ªå®šä¹‰å¢å¼º...
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
])

# ä½¿ç”¨è‡ªå®šä¹‰å˜æ¢åˆ›å»ºæ•°æ®é›†
dataset = AnimeFaceDataset(
    data_dir="/path/to/images",
    image_size=256,
    transform=custom_transform,
)

dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
```

### ç¤ºä¾‹ 4: ç¦ç”¨æ•°æ®å¢å¼º

```python
from dataloader.dataModule import AnimeDataModule

# åˆ›å»ºæ•°æ®æ¨¡å—ï¼Œç¦ç”¨è®­ç»ƒæ—¶çš„æ•°æ®å¢å¼º
datamodule = AnimeDataModule(
    data_dir="/path/to/images",
    train_augment=False,  # ç¦ç”¨å¢å¼º
)
```

## ğŸ“ æ•°æ®æ ¼å¼è¦æ±‚

### ç›®å½•ç»“æ„

æ•°æ®ç›®å½•åº”åŒ…å«å›¾ç‰‡æ–‡ä»¶ï¼ˆ`.png` æˆ– `.jpg` æ ¼å¼ï¼‰ï¼š

```
data_dir/
â”œâ”€â”€ 1.png
â”œâ”€â”€ 2.png
â”œâ”€â”€ 3.jpg
â””â”€â”€ ...
```

### å›¾ç‰‡è¦æ±‚

- **æ ¼å¼**: PNG æˆ– JPG
- **é¢œè‰²æ¨¡å¼**: ä»»æ„ï¼ˆä¼šè‡ªåŠ¨è½¬æ¢ä¸º RGBï¼‰
- **å°ºå¯¸**: ä»»æ„ï¼ˆä¼šè‡ªåŠ¨ resize åˆ°æŒ‡å®šå°ºå¯¸ï¼‰
- **æ•°é‡**: å»ºè®®è‡³å°‘ 1000 å¼ ä»¥ä¸Š

### æ•°æ®é¢„å¤„ç†

æ‰€æœ‰å›¾ç‰‡ä¼šè‡ªåŠ¨è¿›è¡Œä»¥ä¸‹å¤„ç†ï¼š

1. **è½¬æ¢ä¸º RGB**: è‡ªåŠ¨å°†å›¾ç‰‡è½¬æ¢ä¸º RGB æ ¼å¼
2. **Resize**: è°ƒæ•´åˆ° `image_size Ã— image_size`ï¼ˆé»˜è®¤ 256Ã—256ï¼‰
3. **å½’ä¸€åŒ–**: å½’ä¸€åŒ–åˆ° `[-1, 1]` èŒƒå›´

### æ•°æ®å¢å¼ºï¼ˆè®­ç»ƒæ—¶ï¼‰

å¦‚æœ `train_augment=True`ï¼Œè®­ç»ƒæ—¶ä¼šåº”ç”¨ä»¥ä¸‹å¢å¼ºï¼š

- **éšæœºæ°´å¹³ç¿»è½¬**: æ¦‚ç‡ 50%
- **é¢œè‰²æŠ–åŠ¨**: 
  - äº®åº¦: Â±10%
  - å¯¹æ¯”åº¦: Â±10%
  - é¥±å’Œåº¦: Â±10%
  - è‰²è°ƒ: ä¸æ‰°åŠ¨ï¼ˆé¿å…é¢œè‰²åç§»è¿‡å¤§ï¼‰

## âš™ï¸ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. è°ƒæ•´ `num_workers`

æ ¹æ® CPU æ ¸å¿ƒæ•°è°ƒæ•´å·¥ä½œè¿›ç¨‹æ•°ï¼š

```python
import os
num_workers = min(os.cpu_count(), 8)  # ä¸è¶…è¿‡ 8 ä¸ªè¿›ç¨‹

datamodule = AnimeDataModule(
    data_dir="/path/to/images",
    num_workers=num_workers,
)
```

### 2. ä½¿ç”¨ `pin_memory`

å¦‚æœä½¿ç”¨ GPUï¼Œ`pin_memory=True` å¯ä»¥åŠ é€Ÿæ•°æ®ä¼ è¾“ï¼ˆå·²é»˜è®¤å¯ç”¨ï¼‰ã€‚

### 3. è°ƒæ•´ `batch_size`

æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼š

- RTX 4090 (24GB): å»ºè®® `batch_size=32`
- RTX 3090 (24GB): å»ºè®® `batch_size=32`
- RTX 3080 (10GB): å»ºè®® `batch_size=16`

å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œå¯ä»¥å‡å° `batch_size` å¹¶ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ã€‚

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æ‰¾ä¸åˆ°å›¾ç‰‡æ–‡ä»¶

**é”™è¯¯ä¿¡æ¯**: `ValueError: åœ¨ ... ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼ˆ.png æˆ– .jpgï¼‰`

**è§£å†³æ–¹æ¡ˆ**: 
- æ£€æŸ¥ `data_dir` è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®è®¤ç›®å½•ä¸­åŒ…å« `.png` æˆ– `.jpg` æ–‡ä»¶
- æ£€æŸ¥æ–‡ä»¶æƒé™

### Q2: å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
- å‡å° `batch_size`
- å‡å° `num_workers`
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

### Q3: æ•°æ®åŠ è½½é€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**:
- å¢åŠ  `num_workers`
- ä½¿ç”¨ SSD å­˜å‚¨æ•°æ®
- ç¡®ä¿ `pin_memory=True`ï¼ˆå·²é»˜è®¤å¯ç”¨ï¼‰

### Q4: æ•°æ®é›†åˆ’åˆ†ä¸ä¸€è‡´

**è§£å†³æ–¹æ¡ˆ**:
- è®¾ç½®å›ºå®šçš„ `seed` å‚æ•°
- ç¡®ä¿æ¯æ¬¡è¿è¡Œä½¿ç”¨ç›¸åŒçš„ `seed`

## ğŸ“ æµ‹è¯•

è¿è¡Œæ¨¡å—è‡ªå¸¦çš„æµ‹è¯•ä»£ç ï¼š

```bash
cd /home/lick/project/VQ
python dataloader/dataModule.py
```

æµ‹è¯•ä¼šè¾“å‡ºï¼š
- æ‰¾åˆ°çš„å›¾ç‰‡æ•°é‡
- è®­ç»ƒé›†å’ŒéªŒè¯é›†å¤§å°
- æ‰¹æ¬¡å½¢çŠ¶å’Œå€¼åŸŸèŒƒå›´

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªé¡¹ç›®æ ¹ç›®å½•çš„è®¸å¯è¯ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

